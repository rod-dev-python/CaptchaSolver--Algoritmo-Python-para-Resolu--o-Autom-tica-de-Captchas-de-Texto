{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "import pickle\n",
    "from imutils import paths\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D\n",
    "from keras.layers.core import Flatten, Dense\n",
    "from helpers import resize_to_fit\n",
    "# Lista de dados e rótulos\n",
    "dados=[]\n",
    "rotulos=[]\n",
    "# Pasta onde está as imagens de cada letra\n",
    "pasta_base=\"base_letras\"\n",
    "# Retorna o texto do diretório\n",
    "imagens=paths.list_images(pasta_base)\n",
    "# Percorre cada arquivo em imagens\n",
    "for arquivo in imagens:\n",
    "    # Está pegando o nome de cada pasta como rótulo\n",
    "    rotulo = arquivo.split(os.path.sep)[-2]\n",
    "    # Abrindo as imagens\n",
    "    imagem=cv2.imread(arquivo)\n",
    "    # Convertendo para escala cinza\n",
    "    imagem = cv2.cvtColor(imagem, cv2.COLOR_BGR2GRAY)\n",
    "    # alterando o tamanho da imagem\n",
    "    imagem = resize_to_fit(imagem, 20, 20)\n",
    "    # Adicionando 1 dimensãoa imagem, característica do modelo\n",
    "    imagem = np.expand_dims(imagem, axis=2)\n",
    "    # Adiciando os dados as listas de imagens e rotulos\n",
    "    rotulos.append(rotulo)\n",
    "    dados.append(imagem)\n",
    "# Normalizando as imagens e atrituindo um array a cada variável.\n",
    "dados = np.array(dados, dtype=\"float\")/ 255\n",
    "rotulo = np.array(rotulos)\n",
    "\n",
    "# Separação em dados de treino (75%) e teste (25%)\n",
    "(X_train, X_test, Y_train, Y_test) = train_test_split(dados, rotulos, test_size=0.25, random_state=0)\n",
    "\n",
    "# Converter com one-hot encoding\n",
    "lb = LabelBinarizer().fit(Y_train)\n",
    "Y_train=lb.transform(Y_train)\n",
    "Y_test=lb.transform(Y_test)\n",
    "\n",
    "# Salvar o LabelBinarizer em um arquivo com pickle\n",
    "with open('rotulos_do_modelo.dat', 'wb') as arquivo_pickle:\n",
    "    pickle.dump(lb, arquivo_pickle)\n",
    "\n",
    "# Criando modelo\n",
    "modelo = Sequential()\n",
    "# Criando a 1 camada da rede neural\n",
    "modelo.add(Conv2D(20, (5, 5), padding=\"same\", input_shape=(20, 20, 1), activation=\"relu\"))\n",
    "modelo.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "# Criando a 2 camada da rede neural\n",
    "modelo.add(Conv2D(50, (5, 5), padding=\"same\", activation=\"relu\"))\n",
    "modelo.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "# Criando a 3 camada da rede neural\n",
    "modelo.add(Flatten())\n",
    "modelo.add(Dense(500, activation=\"relu\"))\n",
    "# Criando a camada de saida\n",
    "# \"26\" é o número de saídas, pode ser alterado para retornar as possibilidades, neste caso é 26 lestras do alfabeto\n",
    "modelo.add(Dense(26, activation=\"softmax\"))\n",
    "# Compilar todas as camadas\n",
    "modelo.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "# Treinar a IA /epochs/ Quantas vezes passa pelo processo de treino, pode ser alterado de acordo com a necessidade /batch_size/ é o número de saídas citado acima\n",
    "modelo.fit(X_train, Y_train, validation_data=(X_test, Y_test), batch_size=26, epochs=10, verbose=0)\n",
    "\n",
    "# Salvar modelo em um arquivo\n",
    "modelo.save(\"modelo_treinado.hdf5\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
